{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndo4ERqnwQOU"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "MTKwbguKwT4R"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNT-mlFwxVM"
   },
   "source": [
    "# Introducción a los autocodificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TD5ZrvEMbhZ"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/autoencoder\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/autoencoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/autoencoder.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     Ver código fuente en GitHub</a>\n",
    "</td>\n",
    "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/autoencoder.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar notebook</a>   </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITZuApL56Mny"
   },
   "source": [
    "En este tutorial, se presentan los autocodificadores con tres ejemplos: fundamentos, eliminación de ruidos y detección de anomalías.\n",
    "\n",
    "Un autocodificador es un tipo de red neuronal especial que es entrenado para que copie su propia entrada en la salida. Por ejemplo, si se ingresa una imagen con una cifra escrita a mano, un autocodificador primero codifica la imagen en una representación latente de menor dimensión, luego vuelve a decodificar la representación latente en una imagen. Un autocodificador aprende a comprimir los datos mientras minimiza errores de reconstrucción.\n",
    "\n",
    "Para obtener más información sobre los autocodificadores, considere leer el capítulo 14 de [Aprendizaje profundo](https://www.deeplearningbook.org/) de Ian Goodfellow, Yoshua Bengio, y Aaron Courville."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Importar TensorFlow y otras bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Cargar el conjunto de datos\n",
    "\n",
    "Para empezar, entrenará un autocodificador básico con el conjunto de datos MNIST de moda. Cada imagen en el conjunto de datos es de 28x28 píxeles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZm503-I_tji"
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEdCXSwCoKok"
   },
   "source": [
    "## Primer ejemplo: autocodificador básico\n",
    "\n",
    "![Basic autoencoder results](images/intro_autoencoder_result.png)\n",
    "\n",
    "Defina un autocodificador con dos capas densas: un `encoder`, que comprime las imágenes en un vector latente de 64 dimensiones y un `decoder`, que reconstruye la imagen original desde el espacio latente.\n",
    "\n",
    "Para definir su modelo, use la [API de subclasificación del modelo de Keras](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MUxidpyChjX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim, shape):\n",
    "    super().__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    # aquí lo arreglamos:\n",
    "    num_pixels = int(np.prod(shape))        # → 784\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(num_pixels, activation='sigmoid'),\n",
    "      layers.Reshape(shape)\n",
    "    ])\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "\n",
    "shape = x_test.shape[1:]\n",
    "latent_dim = 64\n",
    "autoencoder = Autoencoder(latent_dim, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1JlqEIDCI4"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oJSeMTroABs"
   },
   "source": [
    "Entrene el modelo con `x_train` como la entrada y la salida. El `encoder` aprenderá a comprimir los conjuntos de datos de 784 dimensiones en el espacio latente, y el `decoder` aprenderá a reconstruir las imágenes originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1RI9OfHDBsK"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAM1QBhtoC-n"
   },
   "source": [
    "Ahora que el modelo está entrenado, probemos la codificación y decodificación de imágenes en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(x_test[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs[i])\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4gv6G8PoRQE"
   },
   "source": [
    "## Segundo ejemplo: eliminación de ruidos de la imagen\n",
    "\n",
    "![Image denoising results](images/image_denoise_fmnist_results.png)\n",
    "\n",
    "También se puede entrenar un autocodificador para eliminar el ruido de las imágenes. En la siguiente sección, creará una versión con ruido del conjunto de datos MNIST de moda y aplicará ruido aleatorio en cada imagen. Luego, entrenará al autocodificador con una imagen con ruido como entrada y la imagen original como el destino.\n",
    "\n",
    "Importaremos el conjunto de datos para omitir las modificaciones hechas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDYHJA2PCQ3m"
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJZ-TcaqDBr5"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPZl_6P65_8R"
   },
   "source": [
    "Agregamos ruido aleatorio a las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axSMyxC354fc"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRxHe4XXltNd"
   },
   "source": [
    "Trazamos las imágenes con ruido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thKUmbVVCQpt"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy9SY8jGl5aP"
   },
   "source": [
    "### Definir un autocodificador convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vT_BhZngWMwp"
   },
   "source": [
    "En este ejemplo, entrenará un autocodificador convolucional con las capas [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) en el `encoder`, y las capas [Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) en el `decoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5KjoIlYCQko"
   },
   "outputs": [],
   "source": [
    "class Denoise(Model):\n",
    "  def __init__(self):\n",
    "    super(Denoise, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(28, 28, 1)),\n",
    "      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Denoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYKbiDFYCQfj"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IssFr1BNCQX3"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G85xUVBGTAKp"
   },
   "source": [
    "Veamos un resumen del codificador. Note cómo se reduce el tamaño de las imágenes de 28x28 a 7x7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEpxlX6sTEQz"
   },
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDZBfMx1UtXx"
   },
   "source": [
    "El decodificador aumenta el tamaño de las imágenes de 7x7 a 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbeQtYMaUpro"
   },
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7-VAuEy_N6M"
   },
   "source": [
    "Se trazan las imágenes con ruido y las imágenes sin ruido generadas por el autocodificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5IyPi1fCQQz"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfxr9NdBCP_x"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErGrTnWHoUYl"
   },
   "source": [
    "## Tercer ejemplo: detección de anomalías\n",
    "\n",
    "## Descripción general\n",
    "\n",
    "En este ejemplo, entrenará un autocodificador para detectar anomalías en el [conjunto de datos ECG5000](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000). Este conjunto de datos contiene 5000 [electrocardiogramas](https://en.wikipedia.org/wiki/Electrocardiography), cada uno con 140 puntos de datos. Usará una versión simplificada del conjunto de datos, donde cada ejemplo fue etiquetado con el número `0` (que corresponde a un ritmo cardíaco anormal) o con el número `1` (que corresponde a un ritmo cardíaco normal). Lo que se busca es identificar los ritmos anormales.\n",
    "\n",
    "Nota: Este es un conjunto de datos etiquetados, así que podría formularse como un problema de aprendizaje supervisado. El objetivo de este ejemplo es ilustrar los conceptos de detección de anomalías que pueden aplicarse a conjuntos de datos más grandes, donde no hay etiquetas disponibles (por ejemplo, si tiene miles de ritmos cardíacos normales y solo una pequeña cantidad de ritmos cardíacos anormales).\n",
    "\n",
    "¿Cómo se detectan las anomalías con el autocodificador? Recuerde que un autocodificador está entrenado para minimizar los errores de la reconstrucción. Entrenará un autocodificador solo con los ritmos cardíacos normales, y lo usará para reconstruir todos los datos. Nuestra hipótesis es que los ritmos cardíacos anormales presentarán más errores de reconstrucción. Luego de esto, usted clasificará un ritmo como anormal si el error de reconstrucción supera un umbral fijo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5estNaur_Mh"
   },
   "source": [
    "### Cargar datos ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y35nsXLPsDNX"
   },
   "source": [
    "El conjunto de datos que usará se basa en uno de [timeseriesclassification.com](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmKRDJWgsFYa"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
    "raw_data = dataframe.values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmuCPVYKsKKx"
   },
   "outputs": [],
   "source": [
    "# The last element contains the labels\n",
    "labels = raw_data[:, -1]\n",
    "\n",
    "# The other data points are the electrocadriogram data\n",
    "data = raw_data[:, 0:-1]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=21\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byK2vP7hsMbz"
   },
   "source": [
    "Normalizar los datos en `[0,1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgMZVWRKsPx6"
   },
   "outputs": [],
   "source": [
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = tf.cast(train_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdSYr2IPsTiz"
   },
   "source": [
    "Entrenará al autocodificador solo con los ritmos cardíacos normales, que están etiquetados en el conjunto de datos con el número `1`. Separe los ritmos normales de los ritmos anormales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvK4NRe8sVhE"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "\n",
    "normal_train_data = train_data[train_labels]\n",
    "normal_test_data = test_data[test_labels]\n",
    "\n",
    "anomalous_train_data = train_data[~train_labels]\n",
    "anomalous_test_data = test_data[~test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVcTBDo-CqFS"
   },
   "source": [
    "Trace un ECG normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTlMIrpmseYe"
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(np.arange(140), normal_train_data[0])\n",
    "plt.title(\"A Normal ECG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpI9by2ZA0NN"
   },
   "source": [
    "Trace un ECG anormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrpXREF2siBr"
   },
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(np.arange(140), anomalous_train_data[0])\n",
    "plt.title(\"An Anomalous ECG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DS6QKZJslZz"
   },
   "source": [
    "### Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf6owZQDsp9y"
   },
   "outputs": [],
   "source": [
    "class AnomalyDetector(Model):\n",
    "  def __init__(self):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(8, activation=\"relu\")])\n",
    "    \n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(140, activation=\"sigmoid\")])\n",
    "    \n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = AnomalyDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwRpBBbg463S"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuTy60STBEy4"
   },
   "source": [
    "Note como el autocodificador está entrenado solo con los ECG normales, pero se evalúa con todo el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6NFSs-jsty2"
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data, \n",
    "          epochs=20, \n",
    "          batch_size=512,\n",
    "          validation_data=(test_data, test_data),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEexphFwwTQS"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceI5lKv1BT-A"
   },
   "source": [
    "Pronto clasificará un ECG como anormal si el error de reconstrucción es mayor a una desviación estándar de los ejemplos de entrenamiento normales. Primero, trazaremos un ECG normal con el conjunto de entrenamiento, la reconstrucción después de que el autocodificador lo codifique y descodifique  y el error de reconstrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmsk4DuktxJ2"
   },
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(normal_test_data).numpy()\n",
    "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
    "\n",
    "plt.plot(normal_test_data[0], 'b')\n",
    "plt.plot(decoded_data[0], 'r')\n",
    "plt.fill_between(np.arange(140), decoded_data[0], normal_test_data[0], color='lightcoral')\n",
    "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocA_q9ufB_aF"
   },
   "source": [
    "Cree un trazado similar, pero ahora para un ejemplo de prueba anormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNFTuPhLwTBn"
   },
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(anomalous_test_data).numpy()\n",
    "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
    "\n",
    "plt.plot(anomalous_test_data[0], 'b')\n",
    "plt.plot(decoded_data[0], 'r')\n",
    "plt.fill_between(np.arange(140), decoded_data[0], anomalous_test_data[0], color='lightcoral')\n",
    "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocimg3MBswdS"
   },
   "source": [
    "### Detectar anomalías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xnh8wmkDsypN"
   },
   "source": [
    "Detecte anomalías al calcular si la pérdida de la reconstrucción es mayor al umbral fijo. En este tutorial, calculará el error promedio de la media para los ejemplos normales del conjunto de entrenamiento, luego clasificará los ejemplos futuros como anormales si el error de reconstrucción es mayor que la desviación estándar del conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeuT8uTA5Y_w"
   },
   "source": [
    "Trace el error de reconstrucción en los ECG normales del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7FltOnHu4-l"
   },
   "outputs": [],
   "source": [
    "reconstructions = autoencoder.predict(normal_train_data)\n",
    "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
    "\n",
    "plt.hist(train_loss[None,:], bins=50)\n",
    "plt.xlabel(\"Train loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh-3ChEF5hog"
   },
   "source": [
    "Escoja un valor de umbral que esté una desviación estándar por sobre la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82hkl0Chs3P_"
   },
   "outputs": [],
   "source": [
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEGlA1Be50Nj"
   },
   "source": [
    "Nota: Existen otras estrategias que se pueden usar para seleccionar un valor de umbral que se mencionó anteriormente, que debería clasificar a los ejemplos de prueba en anormales, el enfoque correcto dependerá de su conjunto de datos. Puede obtener más información en los enlaces al final de este tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpLSDAeb51D_"
   },
   "source": [
    "SI examina el error de reconstrucción para los ejemplos anormales en el conjunto de prueba, notará que la mayoría tiene un valor de error de reconstrucción más alto que el umbral. Al variar el umbral, puede ajustar la [precisión](https://developers.google.com/machine-learning/glossary#precision) y [coincidencia](https://developers.google.com/machine-learning/glossary#recall) de su clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKVwjQK955Wy"
   },
   "outputs": [],
   "source": [
    "reconstructions = autoencoder.predict(anomalous_test_data)\n",
    "test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n",
    "\n",
    "plt.hist(test_loss[None, :], bins=50)\n",
    "plt.xlabel(\"Test loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFVk_XGE6AX2"
   },
   "source": [
    "Clasifique un ECG como anormal si el valor de error de reconstrucción es mayor que el umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkgJZfhh6CHr"
   },
   "outputs": [],
   "source": [
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  loss = tf.keras.losses.mae(reconstructions, data)\n",
    "  return tf.math.less(loss, threshold)\n",
    "\n",
    "def print_stats(predictions, labels):\n",
    "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
    "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
    "  print(\"Recall = {}\".format(recall_score(labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOcfXfXq6FBd"
   },
   "outputs": [],
   "source": [
    "preds = predict(autoencoder, test_data, threshold)\n",
    "print_stats(preds, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrJRef8Ln945"
   },
   "source": [
    "## Próximos pasos\n",
    "\n",
    "Para obtener más información sobre la detección de anomalías con autocodificadores, échele un vistazo a este [ejemplo interactivo](https://anomagram.fastforwardlabs.com/#/) generado con TensorFlow.js de Victor Dibia. Para ver un caso del mundo real, puede aprender cómo [Airbus detecta anomalías en datos de telemetría de ISS](https://blog.tensorflow.org/2020/04/how-airbus-detects-anomalies-iss-telemetry-data-tfx.html) con TensorFlow. Para más información sobre los fundamentos, considere esta [entrada de blog](https://blog.keras.io/building-autoencoders-in-keras.html) de François Chollet. Para más detalles, lea el capítulo 14 de [Aprendizaje profundo](https://www.deeplearningbook.org/) de Ian Goodfellow, Yoshua Bengio, y Aaron Courville.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndo4ERqnwQOU"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "MTKwbguKwT4R"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNT-mlFwxVM"
   },
   "source": [
    "# Autocodificador variacional convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TD5ZrvEMbhZ"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/cvae\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
    "</td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/cvae.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/cvae.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     Ver código fuente en GitHub</a>\n",
    "</td>\n",
    "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/cvae.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar el bloc de notas</a>\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITZuApL56Mny"
   },
   "source": [
    "En este cuaderno se enseña cómo entrenar un autocodificador variacional (VAE por sus siglas en inglés) ([1](https://arxiv.org/abs/1312.6114), [2](https://arxiv.org/abs/1401.4082)) en el conjunto de datos MNIST. Un VAE es un enfoque probabilístico del autocodificador, es un modelo que toma datos de entrada de alta dimensión y los comprime en una representación más pequeña. A diferencia de un autocodificador tradicional, que mapea la entrada en un vector latente, un VAE mapea los datos de entrada en parámetros de distribución de probabilidad, tales como la media y la varianza de una gaussiana. Este enfoque produce un espacio de latente continuo y estructurado, que sirve para generar una imagen.\n",
    "\n",
    "![CVAE image latent space](images/cvae_latent_space.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-JuIu2N_SQf"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-probability\n",
    "\n",
    "# to generate gifs\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Cargar el conjunto de datos MNIST\n",
    "\n",
    "Cada imagen de MNIST es originalmente un vector de 784 enteros, cada uno de entre 0 y 255 y representan la intensidad de un pixel. Modele cada pixel con la distribución de Bernoulli en nuestro modelo y convierta el conjunto de datos en binario de forma estática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "def preprocess_images(images):\n",
    "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
    "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "batch_size = 32\n",
    "test_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIGN6ouoQxt3"
   },
   "source": [
    "## Usar *tf.data* para poner los datos en lotes y en orden aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n",
    "                 .shuffle(train_size).batch(batch_size))\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n",
    "                .shuffle(test_size).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Definir las redes del codificador y del decodificador con *tf.keras.Sequential*\n",
    "\n",
    "En este ejemplo de VAE, use dos ConvNets pequeños para las redes del codificador y del decodificador. En la documentación, también se las conoce como inferencia/reconocimiento y modelos generativos respectivamente. Use `tf.keras.Sequential` para simplificar la implementación. Dejemos que $x$ y $z$ denoten la observación y la variable de latente respectivamente en las siguientes descripciones.\n",
    "\n",
    "### Red del codificador\n",
    "\n",
    "Define la distribución posterior aproximada de $q(z|x)$, que toma como entrada una observación y tiene como salida un conjunto de parámetros para especificar la distribución condicional de la representación latente $z$. En este ejemplo, simplemente modele la distribución como una gaussiana diagonal y la salida de la red será los parámetros de la media y de la varianza logarítmica de una gaussiana factorizada. Tiene como salida directamente el logaritmo de la varianza logarítmica en vez de la varianza para conservar la estabilidad numérica.\n",
    "\n",
    "### Red del decodificador\n",
    "\n",
    "Define la distribución condicional de la observación $p(x|z)$, que toma una muestra de latente $z$ como entrada y tiene como salida los parámetros para una distribución condicional de la observación. Modele la distribución latente antes de $p(z)$ como una gaussiana de unidad.\n",
    "\n",
    "### Engaño de reparametrización\n",
    "\n",
    "Para generar una muestra $z$ para el decodificador durante el entrenamiento, puede tomar una muestra de la distribución latente definida por los parámetros que salieron del codificador, al recibir una observación de entrada $x$. Sin embargo, esta operación de muestra crea un cuello de botella porque la retropropagación no puede fluir a través de un nodo aleatorio.\n",
    "\n",
    "Para arreglar esto, use un engaño de reparametrización. En nuestro ejemplo, usted aproximará $z$ mediante el uso de los parámetros del decodificador y otro parámetro $\\epsilon$ de la siguiente manera:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon$$\n",
    "\n",
    "donde $\\mu$ y $\\sigma$ representan la desviación media y estándar de una distribución gaussiana respectivamente. Pueden derivarse de la salida del decodificador. El $\\epsilon$ puede ser considerado como un ruido aleatorio para conservar la estocasticidad de $z$. Genere $\\epsilon$ a partir de una distribución normal estándar.\n",
    "\n",
    "La variable latente $z$ ahora se genera mediante la función de $\\mu$, $\\sigma$ y $\\epsilon$, que permitirá que el modelo retropropague gradientes en el codificador a través de $\\mu$ y $\\sigma$ respectivamente, mientras conserva la estocasticidad a través de $\\epsilon$.\n",
    "\n",
    "### La arquitectura de la red\n",
    "\n",
    "Para la red del codificador, use dos capas convolucionales seguidas de una capa completamente conectada. En la red del decodificador, replique esta arquitectura usando una capa completamente conectada seguida de tres capas de convolución transpuesta (también conocidas como capas deconvolucionales en algunos contextos). Nota, es común evitar el uso de normalización de lotes cuando se entrenan las VAE, ya que la estocasticidad adicional causada por el uso de mini lotes puede agravar la inestabilidad además de la estocasticidad de las muestras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGLbvBEmjK0a"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Definir la función de pérdida y el optimizador\n",
    "\n",
    "Las VAE entrenan al maximizar el límite inferior de evidencia (ELBO, por sus siglas en inglés) en la probabilidad logarítmica marginal:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "En la práctica, optimice el cálculo estimado de Monte Carlo de la muestra única del siguiente valor esperado:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$ donde $z$ es una muestra de $q(z|x)$.\n",
    "\n",
    "Nota: También puede calcular analíticamente el término KL, pero en este caso puede incorporar los tres términos en el estimador de Monte Carlo para que sea más simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "- Primero, iteramos el conjunto de datos\n",
    "- Durante cada iteración, pase la imagen al codificador para obtener un conjunto de parámetros de la media y de la varianza de logaritmos de la posterior aproximada $q(z|x)$\n",
    "- luego aplique el *engaño de reparametrización* para tomar una muestra de $q(z|x)$\n",
    "- Por último, pase las muestras reparametrizadas al decodificador para obtener los logit de la distribución generativa $p(x|z)$\n",
    "- Nota: Ya que se usó el conjunto de datos cargado mediante Keras con 60k puntos de datos en el conjunto de entrenamiento y 10k puntos de datos en el conjunto de prueba, nuestro ELBO resultante en el conjunto de prueba es un poco más alto que los resultados registrados en la documentación que usa una binarización dinámica de la MNIST de Larochelle.\n",
    "\n",
    "### Generar imágenes\n",
    "\n",
    "- Después del entrenamiento, es hora de generar algunas imágenes\n",
    "- Para empezar,  tome una muestra del conjunto de vectores latentes de la gaussiana de unidad antes de la distribución $p(z)$\n",
    "- Luego de esto, el generador convertirá la muestra latente  $z$ en logits de observación, lo que resultará en una distribución $p(x|z)$\n",
    "- Aquí, puede trazar las probabilidades de las distribuciones de Bernoulli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "  mean, logvar = model.encode(test_sample)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  predictions = model.sample(z)\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swCyrbqQQ-Ri"
   },
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "for test_batch in test_dataset.take(1):\n",
    "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  start_time = time.time()\n",
    "  for train_x in train_dataset:\n",
    "    train_step(model, train_x, optimizer)\n",
    "  end_time = time.time()\n",
    "\n",
    "  loss = tf.keras.metrics.Mean()\n",
    "  for test_x in test_dataset:\n",
    "    loss(compute_loss(model, test_x))\n",
    "  elbo = -loss.result()\n",
    "  display.clear_output(wait=False)\n",
    "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "  generate_and_save_images(model, epoch, test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "### Mostrar una imagen generada en la última época del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epoch))\n",
    "plt.axis('off')  # Display images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywiH3nL8guF"
   },
   "source": [
    "### Mostrar un GIF animado de todas las imágenes guardadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZqAEtdqUmJF"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeunRU6TSumT"
   },
   "source": [
    "### Mostrar una variedad bidimensional de cifras del espacio latente\n",
    "\n",
    "Al ejecutar el siguiente código, se mostrará una distribución continua de diferentes clases de cifras, con cada cifra transformándose en otra en todo el espacio latente bidimensional. Use [TensorFlow Probability](https://www.tensorflow.org/probability) para generar una distribución estándar normal para el espacio latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "mNcaaYPBS3mj"
   },
   "outputs": [],
   "source": [
    "def plot_latent_images(model, n, digit_size=28):\n",
    "  \"\"\"Plots n x n digit images decoded from the latent space.\"\"\"\n",
    "\n",
    "  norm = tfp.distributions.Normal(0, 1)\n",
    "  grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "  image_width = digit_size*n\n",
    "  image_height = image_width\n",
    "  image = np.zeros((image_height, image_width))\n",
    "\n",
    "  for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "      z = np.array([[xi, yi]])\n",
    "      x_decoded = model.sample(z)\n",
    "      digit = tf.reshape(x_decoded[0], (digit_size, digit_size))\n",
    "      image[i * digit_size: (i + 1) * digit_size,\n",
    "            j * digit_size: (j + 1) * digit_size] = digit.numpy()\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  plt.imshow(image, cmap='Greys_r')\n",
    "  plt.axis('Off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-ZG69QCZnGY"
   },
   "outputs": [],
   "source": [
    "plot_latent_images(model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrJRef8Ln945"
   },
   "source": [
    "## Próximos pasos\n",
    "\n",
    "En este tutorial, se explicó cómo implementar un autocodificador variacional convolucional con TensorFlow.\n",
    "\n",
    "Su próximo paso puede ser intentar mejorar la salida del modelo al aumentar el tamaño de la red. Por ejemplo, puede intentar configurar los parámetros de `filter` para cada una de las capas `Conv2D` y `Conv2DTranspose` a 512. Tenga en cuenta que, para generar el trazado bidimensional de la imagen latente, deberá conservar `latent_dim` en 2. Además, el tiempo de entrenamiento se reducirá a medida que aumente el tamaño de la red.\n",
    "\n",
    "También puede intentar implementar una VAE con un conjunto de datos diferente, como el CIFAR-10.\n",
    "\n",
    "Las VAE pueden implementarse con diferentes estilos y diversas complejidades. Puede encontrar más implementaciones en los siguientes recursos:\n",
    "\n",
    "- [Autocodificador variacional (keras.io)](https://keras.io/examples/generative/vae/)\n",
    "- [Ejemplo de una VAE de la guia \"Escribir capas y modelos personalizados\" (tensorflow.org)](https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example)\n",
    "- [Capas de probabílistica de TFP: Autocodificador variacional](https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE)\n",
    "\n",
    "Si le gustaría obtener más información sobre los detalles de las VAE, vea [Una introducción a los autocodificadores variacionales](https://arxiv.org/abs/1906.02691)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2022 The TensorFlow Compression Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Comprensión de datos aprendida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/data_compression\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     Ver en TensorFlow.org</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/data_compression.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Ejecutar en Google Colab</a>\n",
    "</td>\n",
    "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/es-419/tutorials/generative/data_compression.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     Ver código fuente en GitHub</a>\n",
    "</td>\n",
    "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/es-419/tutorials/generative/data_compression.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar bloc de notas</a>\n",
    "</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Descripción general\n",
    "\n",
    "En este cuaderno se muestra como realizar la compresión con pérdida de datos con redes neuronales y [TensorFlow Compression](https://github.com/tensorflow/compression).\n",
    "\n",
    "La compresión con pérdida de datos implica una compensación entre la **tasa**, el número previsto de bits que se necesitan para codificar una muestra, y la **distorsión**, el error previsto en la reconstrucción de la muestra.\n",
    "\n",
    "Los ejemplos siguientes usan un modelo de tipo autocodificador que comprime imágenes del conjunto de datos MNIST. El método se basa en el artículo [Compresión optimizada de imágenes de extremo a extremo](https://arxiv.org/abs/1611.01704).\n",
    "\n",
    "Puede encontrar más información sobre la compresión aprendida de datos en [este artículo](https://arxiv.org/abs/2007.03034) destinado a personas con conocimientos de la compresión de datos clásica o en [este estudio](https://arxiv.org/abs/2202.06533) para la audiencia de aprendizaje automático.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Preparación\n",
    "\n",
    "Instale Tensorflow Compression a través de `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K489KsEgxuLI"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Installs the latest version of TFC compatible with the installed TF version.\n",
    "\n",
    "read MAJOR MINOR <<< \"$(pip show tensorflow | perl -p -0777 -e 's/.*Version: (\\d+)\\.(\\d+).*/\\1 \\2/sg')\"\n",
    "pip install \"tensorflow-compression<$MAJOR.$(($MINOR+1))\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfVAmHCVxpTS"
   },
   "source": [
    "Importe las dependencias de la biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqR2PQG4ZaZ0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_compression as tfc\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsncKT2iymgQ"
   },
   "source": [
    "## Definir el modelo de entrenamiento.\n",
    "\n",
    "Ya que el modelo se parece a un autocodificador y necesitamos que realice un conjunto de funciones diferentes durante el entrenamiento e inferencia, la instalación es un poco diferente a la de un clasificador, por ejemplo.\n",
    "\n",
    "El modelo de entrenamiento consiste en tres partes:\n",
    "\n",
    "- la transformación de **análisis** (o codificador), que convierte la imagen en un espacio latente,\n",
    "- la transformación de **síntesis** (o decodificador), que vuelve a convertir el espacio latente en un espacio de imagen, y\n",
    "- un modelo de **inferencia** y entrópico, que modela las probabilidades marginales de los latentes.\n",
    "\n",
    "Primero, defina las transformaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yZESLgW-vp1"
   },
   "outputs": [],
   "source": [
    "def make_analysis_transform(latent_dims):\n",
    "  \"\"\"Creates the analysis (encoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2D(\n",
    "          50, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          latent_dims, use_bias=True, activation=None, name=\"fc_2\"),\n",
    "  ], name=\"analysis_transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sHdYBzF2xcu"
   },
   "outputs": [],
   "source": [
    "def make_synthesis_transform():\n",
    "  \"\"\"Creates the synthesis (decoder) transform.\"\"\"\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          500, use_bias=True, activation=\"leaky_relu\", name=\"fc_1\"),\n",
    "      tf.keras.layers.Dense(\n",
    "          2450, use_bias=True, activation=\"leaky_relu\", name=\"fc_2\"),\n",
    "      tf.keras.layers.Reshape((7, 7, 50)),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          20, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_1\"),\n",
    "      tf.keras.layers.Conv2DTranspose(\n",
    "          1, 5, use_bias=True, strides=2, padding=\"same\",\n",
    "          activation=\"leaky_relu\", name=\"conv_2\"),\n",
    "  ], name=\"synthesis_transform\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYC8tHhkxTlK"
   },
   "source": [
    "El entrenador conserva una instancia de ambas transformaciones y también los parámetros de la inferencia.\n",
    "\n",
    "Se instala su método `call` para calcular:\n",
    "\n",
    "- la **tasa**, un cálculo estimado de la cantidad de bits necesarios para representar un lote de cifras y\n",
    "- la **distorsión**, la diferencia media absoluta entre los píxeles de las cifras originales y sus reconstrucciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ROn2DbzsBirI"
   },
   "outputs": [],
   "source": [
    "class MNISTCompressionTrainer(tf.keras.Model):\n",
    "  \"\"\"Model that trains a compressor/decompressor for MNIST.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dims):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = make_analysis_transform(latent_dims)\n",
    "    self.synthesis_transform = make_synthesis_transform()\n",
    "    self.prior_log_scales = tf.Variable(tf.zeros((latent_dims,)))\n",
    "\n",
    "  @property\n",
    "  def prior(self):\n",
    "    return tfc.NoisyLogistic(loc=0., scale=tf.exp(self.prior_log_scales))\n",
    "\n",
    "  def call(self, x, training):\n",
    "    \"\"\"Computes rate and distortion losses.\"\"\"\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    x = tf.reshape(x, (-1, 28, 28, 1))\n",
    "\n",
    "    # Compute latent space representation y, perturb it and model its entropy,\n",
    "    # then compute the reconstructed pixel-level representation x_hat.\n",
    "    y = self.analysis_transform(x)\n",
    "    entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "        self.prior, coding_rank=1, compression=False)\n",
    "    y_tilde, rate = entropy_model(y, training=training)\n",
    "    x_tilde = self.synthesis_transform(y_tilde)\n",
    "\n",
    "    # Average number of bits per MNIST digit.\n",
    "    rate = tf.reduce_mean(rate)\n",
    "\n",
    "    # Mean absolute difference across pixels.\n",
    "    distortion = tf.reduce_mean(abs(x - x_tilde))\n",
    "\n",
    "    return dict(rate=rate, distortion=distortion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEXbp9RV3kRX"
   },
   "source": [
    "### Calcular la tasa y la distorsión.\n",
    "\n",
    "Vamos paso a paso, usaremos una imagen del conjunto de datos de entrenamiento. Cargue el conjunto de datos MNIST para el entrenamiento y la validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FV99WTrIBen"
   },
   "outputs": [],
   "source": [
    "training_dataset, validation_dataset = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwKgNTg_QfjH"
   },
   "source": [
    "Y extraiga una imagen $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-BSdeHcPBBf"
   },
   "outputs": [],
   "source": [
    "(x, _), = validation_dataset.take(1)\n",
    "\n",
    "plt.imshow(tf.squeeze(x))\n",
    "print(f\"Data type: {x.dtype}\")\n",
    "print(f\"Shape: {x.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8IvuFkrRJIa"
   },
   "source": [
    "Para obtener la representación latente $y$, necesitamos convertirla en `float32`, agregar una dimensión del lote y pasarla por la transformación de análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA0DOWq23lEq"
   },
   "outputs": [],
   "source": [
    "x = tf.cast(x, tf.float32) / 255.\n",
    "x = tf.reshape(x, (-1, 28, 28, 1))\n",
    "y = make_analysis_transform(10)(x)\n",
    "\n",
    "print(\"y:\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTojJQvZT8SX"
   },
   "source": [
    "Los latentes serán cuantificados durante el periodo de prueba. Para modelarlo de manera diferenciable durante el entrenamiento, agregamos ruido uniforme en el intervalo $(-.5, .5)$ y llamamos al resultado $\\tilde y$. Esta es la misma terminología que se usa en el artículo [Compresión optimizada de imágenes de extremo a extremo](https://arxiv.org/abs/1611.01704)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Spr3503OUOFQ"
   },
   "outputs": [],
   "source": [
    "y_tilde = y + tf.random.uniform(y.shape, -.5, .5)\n",
    "\n",
    "print(\"y_tilde:\", y_tilde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hRN89R7SA3U"
   },
   "source": [
    "La \"inferencia\" es la densidad de la probabilidad que entrenamos para modelar la distribución marginal de los latentes con ruido. Por ejemplo, puede ser un conjunto de [distribuciones logísticas](https://en.wikipedia.org/wiki/Logistic_distribution) con diferentes escalas para cada dimensión latente. `tfc.NoisyLogistic` explica el hecho de que las latentes tengan ruido agregado. Ya que la escala está cerca del cero, una distribución logística se encuentra cerca de la delta de Dirac (pico), pero el ruido agregado causa la distribución \"ruidosa\" para acercarse más a la distribución uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tmA1Bw7ReMY"
   },
   "outputs": [],
   "source": [
    "prior = tfc.NoisyLogistic(loc=0., scale=tf.linspace(.01, 2., 10))\n",
    "\n",
    "_ = tf.linspace(-6., 6., 501)[:, None]\n",
    "plt.plot(_, prior.prob(_));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NSWtBZmUvVY"
   },
   "source": [
    "Durante el entrenamiento, `tfc.ContinuousBatchedEntropyModel` agrega ruido uniforme y usa el ruido y la inferencia para calcular un límite superior (diferenciable) en la tasa (cantidad promedio de bits necesarios para codificar la representación latente). Ese límite puede minimizarse como una pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFuGlyJuThBC"
   },
   "outputs": [],
   "source": [
    "entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "    prior, coding_rank=1, compression=False)\n",
    "y_tilde, rate = entropy_model(y, training=True)\n",
    "\n",
    "print(\"rate:\", rate)\n",
    "print(\"y_tilde:\", y_tilde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyr8DGgmWd32"
   },
   "source": [
    "Por último, se pasan las latentes con ruido a través de la transformación de síntesis para producir la reconstrucción de la imagen $\\tilde x$. La distorsión es el error entre la imagen original y la reconstrucción. Obviamente, si no se entrenan las transformaciones, la reconstrucción no es muy útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtmI0xGEVym0"
   },
   "outputs": [],
   "source": [
    "x_tilde = make_synthesis_transform()(y_tilde)\n",
    "\n",
    "# Mean absolute difference across pixels.\n",
    "distortion = tf.reduce_mean(abs(x - x_tilde))\n",
    "print(\"distortion:\", distortion)\n",
    "\n",
    "x_tilde = tf.saturate_cast(x_tilde[0] * 255, tf.uint8)\n",
    "plt.imshow(tf.squeeze(x_tilde))\n",
    "print(f\"Data type: {x_tilde.dtype}\")\n",
    "print(f\"Shape: {x_tilde.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVz3I7E8ecij"
   },
   "source": [
    "Para cada lote de cifras, si se llama a `MNISTCompressionTrainer`, este produce la tasa y la distorsión como un promedio sobre ese lote:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICJnjj1LeB8L"
   },
   "outputs": [],
   "source": [
    "(example_batch, _), = validation_dataset.batch(32).take(1)\n",
    "trainer = MNISTCompressionTrainer(10)\n",
    "example_output = trainer(example_batch)\n",
    "\n",
    "print(\"rate: \", example_output[\"rate\"])\n",
    "print(\"distortion: \", example_output[\"distortion\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgdfRtmee5Mn"
   },
   "source": [
    "En la siguiente sección, instalaremos el modelo para hacer que el gradiente descienda en las dos pérdidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKGVwv5MAq6w"
   },
   "source": [
    "## Entrenar el modelo.\n",
    "\n",
    "Compilamos el entrenador para que optimice la tasa y la distorsión lagareanas, es decir, la suma de la tasa y la distorsión, donde uno de los términos se evalúa con el parámetro $\\lambda$ de Lagrange.\n",
    "\n",
    "Esta función de pérdida afecta a diferentes partes del modelo de distintas formas:\n",
    "\n",
    "- La transformación de análisis se entrena para producir una representación latente que logre la compensación deseada entre la tasa y la distorsión.\n",
    "- La transformación de síntesis se entrena para minimizar la distorsión, según la representación latente.\n",
    "- Los parámetros de la inferencia se entrenan para minimizar la tasa según la representación latente. Es idéntico a encajar la inferencia en la distribución marginal de latentes en un sentido de probabilidad máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5mm1aDkcgAf"
   },
   "outputs": [],
   "source": [
    "def pass_through_loss(_, x):\n",
    "  # Since rate and distortion are unsupervised, the loss doesn't need a target.\n",
    "  return x\n",
    "\n",
    "def make_mnist_compression_trainer(lmbda, latent_dims=50):\n",
    "  trainer = MNISTCompressionTrainer(latent_dims)\n",
    "  trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    # Just pass through rate and distortion as losses/metrics.\n",
    "    loss=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    metrics=dict(rate=pass_through_loss, distortion=pass_through_loss),\n",
    "    loss_weights=dict(rate=1., distortion=lmbda),\n",
    "  )\n",
    "  return trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPwd4DTs3Mfr"
   },
   "source": [
    "Luego, entrene el modelo. Las anotaciones de personas no son necesarias aquí, ya que solo queremos comprimir las imágenes, por eso las abandonamos con `map` y en su lugar agregamos destinos \"de relleno\" para la tasa y la distorsión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNBpCTgzAV7M"
   },
   "outputs": [],
   "source": [
    "def add_rd_targets(image, label):\n",
    "  # Training is unsupervised, so labels aren't necessary here. However, we\n",
    "  # need to add \"dummy\" targets for rate and distortion.\n",
    "  return image, dict(rate=0., distortion=0.)\n",
    "\n",
    "def train_mnist_model(lmbda):\n",
    "  trainer = make_mnist_compression_trainer(lmbda)\n",
    "  trainer.fit(\n",
    "      training_dataset.map(add_rd_targets).batch(128).prefetch(8),\n",
    "      epochs=15,\n",
    "      validation_data=validation_dataset.map(add_rd_targets).batch(128).cache(),\n",
    "      validation_freq=1,\n",
    "      verbose=1,\n",
    "  )\n",
    "  return trainer\n",
    "\n",
    "trainer = train_mnist_model(lmbda=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td4xuttmCd7T"
   },
   "source": [
    "## Comprimir algunas imágenes MNIST.\n",
    "\n",
    "Para comprimir y descomprimir durante el periodo de prueba, dividimos el modelo de entrenamiento en dos partes:\n",
    "\n",
    "- La parte del codificador que consiste en la transformación de análisis y el modelo de entropía.\n",
    "- La parte del decodificador que consiste en la transformación de síntesis y el mismo modelo de entropía.\n",
    "\n",
    "En este momento, las latentes no tienen ruido agregado, pero se cuantificarán y luego se comprimirán sin pérdida así que pondremos nombres nuevos. Los llamamos y a la imagen de reconstrucción $\\hat x$ y $\\hat y$, respectivamente (como se presenta en [Comprensión optimizada de imágenes de extremo a extremo](https://arxiv.org/abs/1611.01704))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBRAPa5jksss"
   },
   "outputs": [],
   "source": [
    "class MNISTCompressor(tf.keras.Model):\n",
    "  \"\"\"Compresses MNIST images to strings.\"\"\"\n",
    "\n",
    "  def __init__(self, analysis_transform, entropy_model):\n",
    "    super().__init__()\n",
    "    self.analysis_transform = analysis_transform\n",
    "    self.entropy_model = entropy_model\n",
    "\n",
    "  def call(self, x):\n",
    "    # Ensure inputs are floats in the range (0, 1).\n",
    "    x = tf.cast(x, self.compute_dtype) / 255.\n",
    "    y = self.analysis_transform(x)\n",
    "    # Also return the exact information content of each digit.\n",
    "    _, bits = self.entropy_model(y, training=False)\n",
    "    return self.entropy_model.compress(y), bits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSZ0X2xPnkN-"
   },
   "outputs": [],
   "source": [
    "class MNISTDecompressor(tf.keras.Model):\n",
    "  \"\"\"Decompresses MNIST images from strings.\"\"\"\n",
    "\n",
    "  def __init__(self, entropy_model, synthesis_transform):\n",
    "    super().__init__()\n",
    "    self.entropy_model = entropy_model\n",
    "    self.synthesis_transform = synthesis_transform\n",
    "\n",
    "  def call(self, string):\n",
    "    y_hat = self.entropy_model.decompress(string, ())\n",
    "    x_hat = self.synthesis_transform(y_hat)\n",
    "    # Scale and cast back to 8-bit integer.\n",
    "    return tf.saturate_cast(tf.round(x_hat * 255.), tf.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI7rxeOUDnaC"
   },
   "source": [
    "Cuando se crea una instancia con `compression=True`, el modelo de entropía convierte la inferencia aprendida en tablas para un algoritmo de codificación de rango. Cuando se llama a `compress()`, se invoca este algoritmo para convertir el vector del espacio latente en secuencias de bit. El largo de cada cadena de texto binaria se aproxima al contenido de datos de la latente (la probabilidad logarítmica negativa de la latente bajo la inferencia).\n",
    "\n",
    "El modelo de entropía para comprimir y descomprimir debe ser la misma instancia, porque las tablas de codificación de rango tienen que ser exactamente idénticas en ambos lados. Si no es así, pueden ocurrir errores de decodificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dnm_p7mbnigo"
   },
   "outputs": [],
   "source": [
    "def make_mnist_codec(trainer, **kwargs):\n",
    "  # The entropy model must be created with `compression=True` and the same\n",
    "  # instance must be shared between compressor and decompressor.\n",
    "  entropy_model = tfc.ContinuousBatchedEntropyModel(\n",
    "      trainer.prior, coding_rank=1, compression=True, **kwargs)\n",
    "  compressor = MNISTCompressor(trainer.analysis_transform, entropy_model)\n",
    "  decompressor = MNISTDecompressor(entropy_model, trainer.synthesis_transform)\n",
    "  return compressor, decompressor\n",
    "\n",
    "compressor, decompressor = make_mnist_codec(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYu5sVVH3YMv"
   },
   "source": [
    "Tome 16 imágenes del conjunto de datos de validación. Puede seleccionar un subconjunto diferente si cambia el argumento a `skip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAxArlU728K5"
   },
   "outputs": [],
   "source": [
    "(originals, _), = validation_dataset.batch(16).skip(3).take(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHeN_ny929YS"
   },
   "source": [
    "Comprímalas en cadenas de texto y lleve la cuenta de sus contenidos de datos en bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smOk42gQ3IXv"
   },
   "outputs": [],
   "source": [
    "strings, entropies = compressor(originals)\n",
    "\n",
    "print(f\"String representation of first digit in hexadecimal: 0x{strings[0].numpy().hex()}\")\n",
    "print(f\"Number of bits actually needed to represent it: {entropies[0]:0.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j9R4bTT3Qhl"
   },
   "source": [
    "Descomprima las cadena de texto a imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOP6pEqU3P0w"
   },
   "outputs": [],
   "source": [
    "reconstructions = decompressor(strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWo0Q-vy23tt"
   },
   "source": [
    "Muestre cada una de las 16 cifras originales junto a sus representaciones binarias y la cifra reconstruida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jU5IqzZzeEpf"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "def display_digits(originals, strings, entropies, reconstructions):\n",
    "  \"\"\"Visualizes 16 digits together with their reconstructions.\"\"\"\n",
    "  fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(12.5, 5))\n",
    "  axes = axes.ravel()\n",
    "  for i in range(len(axes)):\n",
    "    image = tf.concat([\n",
    "        tf.squeeze(originals[i]),\n",
    "        tf.zeros((28, 14), tf.uint8),\n",
    "        tf.squeeze(reconstructions[i]),\n",
    "    ], 1)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].text(\n",
    "        .5, .5, f\"→ 0x{strings[i].numpy().hex()} →\\n{entropies[i]:0.2f} bits\",\n",
    "        ha=\"center\", va=\"top\", color=\"white\", fontsize=\"small\",\n",
    "        transform=axes[i].transAxes)\n",
    "    axes[i].axis(\"off\")\n",
    "  plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "km9PqVEtPJPc"
   },
   "outputs": [],
   "source": [
    "display_digits(originals, strings, entropies, reconstructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzlrIOiYOzJc"
   },
   "source": [
    "Preste atención a como a longitud de la cadena codificada es diferente al contenido de datos de cada cifra.\n",
    "\n",
    "Esto se debe a que el proceso de codificación de rango funciona con probabilidades discretas y tiene una breve sobrecarga. Por lo tanto, especialmente para las cadenas de texto cortas, la correspondencia solo es aproximada. Sin embargo, la codificación de rango es **óptima de forma asintótica**: en el límite, el conteo esperado de bits se acercará a la entropía cruzada (el contenido de datos esperado) para el cual el término de la tasa en el modelo de entrenamiento es un límite superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78qIG8t8FvJW"
   },
   "source": [
    "## La compensación de tasa y distorsión\n",
    "\n",
    "Anteriormente, se entrenó el modelo para una compensación específica (dada por `lmbda=2000`) entre la cantidad promedio de bits usados para representar cada cifra y el error resultante durante la reconstrucción.\n",
    "\n",
    "¿Qué sucede si intentamos el experimento de nuevo con diferentes valores?\n",
    "\n",
    "Empecemos por reducir $\\lambda$ a 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iFcAD0WF78p"
   },
   "outputs": [],
   "source": [
    "def train_and_visualize_model(lmbda):\n",
    "  trainer = train_mnist_model(lmbda=lmbda)\n",
    "  compressor, decompressor = make_mnist_codec(trainer)\n",
    "  strings, entropies = compressor(originals)\n",
    "  reconstructions = decompressor(strings)\n",
    "  display_digits(originals, strings, entropies, reconstructions)\n",
    "\n",
    "train_and_visualize_model(lmbda=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5OkgJMObMc"
   },
   "source": [
    "La tasa de bits de nuestro código disminuye, al igual que la fidelidad de las cifras. Sin embargo, la mayoría de las cifras siguen siendo reconocibles.\n",
    "\n",
    "Reduzcamos $\\lambda$ un poco más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQp9_9_5GcxH"
   },
   "outputs": [],
   "source": [
    "train_and_visualize_model(lmbda=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ELLMAN1OwMQ"
   },
   "source": [
    "Ahora, las cadenas de texto se van acortando, un byte por cifra. Pero esto sucede a un costo. Cada vez más cifras se vuelven irreconocibles.\n",
    "\n",
    "Esto demuestra que este modelo es agnóstico a la capacidad humana de reconocer los errores, solo mide la desviación absoluta en términos de valores de píxeles. Para lograr una calidad de imagen mejor percibida, tendremos que reemplazar la pérdida de píxeles con la pérdida de percepción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9cWHtH0LP_r"
   },
   "source": [
    "## Usar el decodificador como modelo generativo.\n",
    "\n",
    "Si ingresamos bits aleatorios en el decodificador, este tomará efectivamente la distribución que el modelo aprendió para representar cifras como muestra.\n",
    "\n",
    "Primero, vuelva a crear la instancia del compresor/descompresor sin una verificación de sanidad que pueda detectar si la cadena de texto de entrada fue decodificada completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnic8YsM0_ke"
   },
   "outputs": [],
   "source": [
    "compressor, decompressor = make_mnist_codec(trainer, decode_sanity_check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86uc9_Is1eeo"
   },
   "source": [
    "Ahora, ingrese cadenas de texto aleatorias con una buena longitud en el descompresor para que pueda decodificar/tomar la muestra de las cifras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4fP7BkqKCHY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "strings = tf.constant([os.urandom(8) for _ in range(16)])\n",
    "samples = decompressor(strings)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(5, 5))\n",
    "axes = axes.ravel()\n",
    "for i in range(len(axes)):\n",
    "  axes[i].imshow(tf.squeeze(samples[i]))\n",
    "  axes[i].axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
